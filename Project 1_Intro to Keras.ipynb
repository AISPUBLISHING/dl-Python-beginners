{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"Intro to Keras.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"DzhMJENIXOI8","colab_type":"text"},"source":["This notebook is an introduction to keras with tutorial of basic model building. We focus on individual functions to build each layer and their parameters along with examples to practically see their results. More advanced concepts e.g. fine-tuning and data augmentation are explained in future notebooks."]},{"cell_type":"markdown","metadata":{"id":"aLzU-UxCXOI-","colab_type":"text"},"source":["# Introduction to Keras Library"]},{"cell_type":"markdown","metadata":{"id":"UnTzhPnZXOI_","colab_type":"text"},"source":["Keras is a deep learning library. Its modular approach and simple design allows us to learn and implement deep learning models easily and quickly. Its design allows us to quickly prototype our models without worrying too much about intricate/complex inner details. Its a high level library, so its synatax is easy to understand."]},{"cell_type":"markdown","metadata":{"id":"HiA-nbJ8XOJB","colab_type":"text"},"source":["## Keras Backend\n","As keras is a high level library, it does not perform low level operations of tensor manipulation e.g. tensor multiplication, addition etc. Rather, it uses third-party specialized libraries to do that. These special libraries are said to be backend engine of keras. From various possible options of keras backend engines: Theano, Tensorflow and CNTK, we can select any one and use it with keras. \n","\n","First, we will use keras backend with tensorflow and understand tensor manipulations in it."]},{"cell_type":"markdown","metadata":{"id":"TqFjEhURXOJC","colab_type":"text"},"source":["### Tensors Manipulation"]},{"cell_type":"code","metadata":{"id":"oeti_T1fXOJE","colab_type":"code","colab":{}},"source":["# Import keras backend to use\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9FguVQYpXOJI","colab_type":"text"},"source":["We will define three tensors of 5 x 5 shape:\n","1. Filled with 0s. \n","2. Filled with 1s\n","3. Filled with random values\n","\n","A simple print statement is not used to show the values of tensor. Keras backend provides get_value function to do that."]},{"cell_type":"code","metadata":{"id":"rmJJrRxZXOJJ","colab_type":"code","colab":{},"outputId":"723df3b9-07b4-402a-fd38-675ecb680eaa"},"source":["zeros_tensor=K.zeros(shape=(5,5))                                        # Initialize a tensor of shape 5 x 5 with all zeros filled\n","ones_tensor= K.ones(shape=(5,5))                                         # Initialize a tensor of shape 5 x 5 with all ones filled\n","rand_tensor=K.random_normal_variable(shape=(5,5),mean=0,scale=3)         # Initialize a random tensor of shape 5 x 5 with mean value = 0 and standard deviation = 3\n","\n","print('zeros tensor: ')\n","print(K.get_value(zeros_tensor))                                         # Print zeros tensor\n","\n","print('\\nones tensor: ')\n","print(K.get_value(ones_tensor))                                          # Print ones tensor\n","\n","print('\\nrandom tensor: ')\n","print(K.get_value(rand_tensor))                                          # Print random tensor\n","\n"," \n","print('\\nShape of random tensor: ',rand_tensor.shape)                    # Shape of the random tensor"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /home/hassan/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","zeros tensor: \n","[[0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0.]]\n","\n","ones tensor: \n","[[1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1.]\n"," [1. 1. 1. 1. 1.]]\n","\n","random tensor: \n","[[-1.9247348   1.7806361   1.2424654   4.1707      0.03489759]\n"," [-1.0863552  -1.686175   -3.4082859  -1.1001399   4.92533   ]\n"," [-0.44365144 -2.1258113   2.6624944  -4.5818515   4.4941826 ]\n"," [-1.6052155  -1.7099472   2.3560743  -1.282958   -1.2331492 ]\n"," [ 0.13307902  1.4599998   3.871846    1.0848838  -0.18272676]]\n","\n","Shape of random tensor:  (5, 5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LO61imwxXOJO","colab_type":"text"},"source":["Now, we will add two tensors together, subtract two tensors and multiply values of two tensors to understand tensor operations. We can use same arithmetic notations for addition and subtraction. The multiplication sign is a little confusing. \n","* For element wise multiplication of two tensors, use **'*'** sign\n","* For multiplication of two tensors, use **K.dot** function"]},{"cell_type":"code","metadata":{"id":"tYvh5AplXOJP","colab_type":"code","colab":{},"outputId":"9f942357-0e84-4819-913b-a3d31e1877f4"},"source":["add_ones_rand = ones_tensor + rand_tensor                                       # Add random tensor with ones tensor\n","sub_rand_ones = rand_tensor - ones_tensor                                       # Subtract ones tensor from random tensor\n","mul_ones_rand = ones_tensor * rand_tensor                                       # Element wise multiply ones and random tensor\n","\n","print('\\nAddition : \\n',K.get_value(add_ones_rand))\n","print('\\nSubtraction : \\n',K.get_value(sub_rand_ones))\n","print('\\nMultiplication: \\n',K.get_value(K.dot(ones_tensor,rand_tensor)))\n","print('\\nElement wise Multiply : \\n',K.get_value(mul_ones_rand))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Addition : \n"," [[-0.92473483  2.780636    2.2424655   5.1707      1.0348976 ]\n"," [-0.08635521 -0.686175   -2.4082859  -0.10013986  5.92533   ]\n"," [ 0.55634856 -1.1258113   3.6624944  -3.5818515   5.4941826 ]\n"," [-0.60521555 -0.7099472   3.3560743  -0.28295803 -0.23314917]\n"," [ 1.133079    2.4599998   4.871846    2.0848837   0.81727326]]\n","\n","Subtraction : \n"," [[-2.9247348   0.7806361   0.24246538  3.1707     -0.96510243]\n"," [-2.0863552  -2.6861749  -4.408286   -2.1001399   3.9253302 ]\n"," [-1.4436514  -3.1258113   1.6624944  -5.5818515   3.4941826 ]\n"," [-2.6052155  -2.709947    1.3560743  -2.282958   -2.233149  ]\n"," [-0.86692095  0.4599998   2.871846    0.08488381 -1.1827267 ]]\n","\n","Multiplication: \n"," [[-4.926878  -2.2812977  6.724594  -1.7093655  8.038535 ]\n"," [-4.926878  -2.2812977  6.724594  -1.7093655  8.038535 ]\n"," [-4.926878  -2.2812977  6.724594  -1.7093655  8.038535 ]\n"," [-4.926878  -2.2812977  6.724594  -1.7093655  8.038535 ]\n"," [-4.926878  -2.2812974  6.724594  -1.7093655  8.038534 ]]\n","\n","Element wise Multiply : \n"," [[-1.9247348   1.7806361   1.2424654   4.1707      0.03489759]\n"," [-1.0863552  -1.686175   -3.4082859  -1.1001399   4.92533   ]\n"," [-0.44365144 -2.1258113   2.6624944  -4.5818515   4.4941826 ]\n"," [-1.6052155  -1.7099472   2.3560743  -1.282958   -1.2331492 ]\n"," [ 0.13307902  1.4599998   3.871846    1.0848838  -0.18272676]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2VNlUtK2XOJS","colab_type":"text"},"source":["## Model Building\n","A deep learning model is a combination of different types of layers (e.g. convolution, pool, fully connected, dropout, activation). In keras, these layers are used as modules and are put together using \"model\" data structure. "]},{"cell_type":"markdown","metadata":{"id":"Qqkyjc9wXOJT","colab_type":"text"},"source":["\n","In keras, we can build our models in two ways:\n","* Using Sequential API\n","* Using Functional API\n","\n","We use sequential API for developing simple models e.g. with no skip connections, no acyclic graphs or multiple outputs. Keras provides 'Sequential' model to put together different modules as a linear stack. For complex architectures (e.g. containing skip connections, cyclic graphs), we use functional API of keras. \n","\n","Following are the steps to build a model using Sequential API:\n","\n","1. First, we define or initialize the model, which means declaring the model as an instance of Sequential Class. This allows us to stack different layers to be used as a model. \n","\n","2. We add different layers to our model using \".add()\" function. \n","\n","3. Then, we compile our model which means, to configure the learning process and includes setting loss function and optimizer for the model or setting learning rate for weight updates during back propagation.\n","\n","4. We train our model by calling \".fit()\" function on our model object. The parameters of fit function include training data, validation data, number of epochs to train the model and batch size.\n","\n","5. Evaluating the model performance on evaluation dataset. We can set a specific metric ('Accuracy', 'F1 score', 'Precision' etc.) to get results in requried units. \n","\n","6. Model Testing on our test set and visualizing the results."]},{"cell_type":"markdown","metadata":{"id":"PIzAWMYeXOJU","colab_type":"text"},"source":["## Layers\n","Here, we will see how to define different modules(layers) in keras and later, we will learn to stack them using Sequential API of keras.\n","### Convolutional Layer\n","We import CNN layers from keras.layers.convolutional. We will consider function for 2D convolution. It has several parameters but we will only discuss the most important ones and relevant to our tutorial here. \n","\n","**Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', activation=None, use_bias=True,data_format=None)**\n","\n","* filters: filters actually tell the number of output channels. Because each filter is trained to look for certain visual feature and outputs a single activation map for that feature. This means, if we have 32 filters, and apply Conv2D on an input tensor, we will get an output tensor with 32 channels.\n","\n","* kernel_size: Kernel_size is an integer or a tuple that specifies the height and width of convolution window. It is effectively our effective receptive field. A large kernel would mean that the kernel is looking at a larger area of image, while a small kernel size means that it focuses on smaller area at one time. \n","\n","* strides: strides is an integer or a tuple that specifies the step for convolution window along height and width. \n","\n","* padding: possible padding options are 'valid' and 'same'. With 'same' option, the output tensor has same shape as input tensor as the image is padded before applying Conv2D.\n","\n","* activation: name of the activation function to be applied on the output of layer. By default, no activation is applied.\n","\n","* use_bias: True if the layer is to use bias vector and False if not.\n","\n","* data_format: This is a string value which defines the ordering of input tensor dimensions. \"channels_last\" corresponds to inputs with shape  (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape  (batch, channels, height, width). By default, it will be the value set in ~/.keras/keras.json or \"channels_last\", if not set in file.\n","\n","This function takes a 4D tensor as input with shape (batch, channels, height, width).\n","\n","See the example below of creating a Convolutional 2D layer:"]},{"cell_type":"code","metadata":{"id":"FrH-msMSXOJV","colab_type":"code","colab":{}},"source":["from keras.layers.convolutional import Conv2D                                   # Import Conv2D submodule from keras' convolutional module\n","from keras import backend as K                                                  # Import keras as backend\n","\n","# Get a layer with padding = 'valid' and another layer with padding = 'same'\n","convlayer_validpadding=Conv2D(1, (3,3), strides=(1, 1), padding='valid', activation=None, use_bias=True,data_format=\"channels_first\")\n","convlayer_samepadding=Conv2D(1, (3,3), strides=(1, 1), padding='same', activation=None, use_bias=True,data_format=\"channels_first\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLTLjOd3XOJY","colab_type":"text"},"source":["We will not initialize a random tensor of batch 1, channel 1, a height and width of 5. We will feed this tensor to our convolution layer and will look at the results. This will help us understand convolution in keras.\n"]},{"cell_type":"code","metadata":{"id":"zQbQXDjDXOJZ","colab_type":"code","colab":{},"outputId":"fce6298f-ffa2-4fbc-ab7b-5082eae181ee"},"source":["# A random tensor of uniform data distribution with shape = (1 x 1 x 5 x 5) with lowest possible value = 0 and highest possible = 255\n","randomtensor=K.random_uniform_variable(shape=(1,1,5,5),low=0,high=255)\n","print('Input tensor: \\n',K.get_value(randomtensor))\n","\n","# Pass this random tensor with shape = (1 x 1 x 5 x 5)  to convolutional layer\n","print('\\nConvolution with valid padding: ')\n","outtensor=convlayer_validpadding(randomtensor)\n","print('Conv output: \\n',K.get_value(outtensor))\n","\n","# Pass this random tensor with shape = (1 x 1 x 5 x 5)  to convolutional layer\n","print('\\nConvolution with same padding: ')\n","outtensor=convlayer_samepadding(randomtensor)\n","print('Conv output: \\n',K.get_value(outtensor))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Input tensor: \n"," [[[[ 65.76495   81.825356  15.02719   36.95554   32.877327]\n","   [209.33842   10.329335 159.12941  137.64525  116.365776]\n","   [240.34006  247.07956   15.511345  55.06701  144.0604  ]\n","   [204.52391  209.58885  156.07443  155.97627  201.62712 ]\n","   [ 42.551273  29.56971   41.977715  67.07628  118.80479 ]]]]\n","\n","Convolution with valid padding: \n","Conv output: \n"," [[[[ -86.29592   -14.984547  -22.486248]\n","   [  62.06592   -38.12681  -119.31634 ]\n","   [ 161.76526   118.06208   -47.397507]]]]\n","\n","Convolution with same padding: \n","Conv output: \n"," [[[[  53.43195    -27.072586   -27.5922      -4.6767797  -28.941502 ]\n","   [  97.45246   -147.2408      32.422558    -1.5409379  -69.10389  ]\n","   [ 136.74294   -132.81952   -147.16383    -45.018234  -103.6035   ]\n","   [ 169.78822   -172.38379   -129.70387     61.254646   -84.2743   ]\n","   [  39.110954  -116.932816   -85.53351    -20.845926  -126.87508  ]]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3E3gDoMDXOJd","colab_type":"text"},"source":["We can see from output above that our output tensor has less width and height in valid padding while we have same width and height in case of same padding."]},{"cell_type":"markdown","metadata":{"id":"wcs7mpqsXOJe","colab_type":"text"},"source":["### Pooling Layer\n","We import pooling layers from keras.layers. We will consider function for MaxPooling2D as we are working with images, for now. The function parameters are same for AveragePooling2D. \n","\n","**MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')**\n","* pool_size: It is the window size that is actually effective receptive field. It is an integer value or a tuple of 2 integers specifying the factors to downscale the input tensor in width and height. A pool_size of (2, 2) will halve the input in both spatial dimension. For a single integer, the same window length will be used for both dimensions.\n","* strides: It defines the steps in width and height dimensions after each operation. It is an integer value or a tuple of 2 integers. If strides=None, the default value used will be pool_size.\n","* padding: It can either be \"same\" or \"valid\". If the height and width of input tensor are perfectly divisible by pool_size, we will have same output for \"same\" and \"valid\" options. But, the outputs will be different in other cases. We will mostly use \"valid\" option in our deep learning models.\n","* data_format: Same as in convolutional layer. It can be \"channels_first\" specifying that the input tensor will have channels as first dimension or \"channels_last\" specifying that the input tensor will have channels as last dimension."]},{"cell_type":"code","metadata":{"id":"q6a_6DRXXOJf","colab_type":"code","colab":{},"outputId":"132e2d6c-6fe0-45a0-fa00-93cf258d0f27"},"source":["from keras.layers import MaxPooling2D                                           # Import MaxPooling2D submodule from keras' layers module\n","from keras import backend as K                                                  # Import keras backend\n","\n","# Intialize two pooling layers: one with 'valid' padding and the other with 'same' padding\n","poollayer_validpadding=MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=\"channels_first\")\n","poollayer_samepadding=MaxPooling2D(pool_size=(2, 2), strides=None, padding='same',data_format=\"channels_first\")\n","\n","# Intiailize a random tensor with lowest value = 0 and highest value = 255\n","randomtensor=K.random_uniform_variable(shape=(1,1,5,5),low=0,high=255)\n","print('Input tensor: \\n',K.get_value(randomtensor))\n","\n","# Pass random tensor to pooling layer with valid padding\n","print('\\nMaxpool with valid padding: ')\n","outtensor=poollayer_validpadding(randomtensor)\n","print('Conv output: \\n',K.get_value(outtensor))\n","\n","# Pass random tensor to pooling layer with same padding\n","print('\\nMaxpool with same padding: ')\n","outtensor=poollayer_samepadding(randomtensor)\n","print('Maxpool output: \\n',K.get_value(outtensor))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Input tensor: \n"," [[[[ 88.08201  254.96082  235.22987   32.803852 237.5966  ]\n","   [ 81.94276  105.93904   27.282171  45.248062 166.89757 ]\n","   [200.07713  245.2447   178.40118   28.157705  49.7963  ]\n","   [ 37.316795 183.24231   39.885426  98.707184  84.3887  ]\n","   [159.07239   17.028164 120.70368   52.929123  69.96987 ]]]]\n","\n","Maxpool with valid padding: \n","Conv output: \n"," [[[[254.96082 235.22987]\n","   [245.2447  178.40118]]]]\n","\n","Maxpool with same padding: \n","Maxpool output: \n"," [[[[254.96082 235.22987 237.5966 ]\n","   [245.2447  178.40118  84.3887 ]\n","   [159.07239 120.70368  69.96987]]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iLwf-SXSXOJk","colab_type":"text"},"source":["### Activation\n","Activations are applied on the output of our model layers. Activations can be applied through activation layer provided by keras.layers.core submodule of keras or activation parameter (or argument) supported by each layer. The activations are also provided through keras.activations submodule.\n","\n","We only specify the name of the activation function as the parameter:\n","\n","**Activation(activation)**\n","\n","* activation: We can choose from several available activation functions: 'relu', 'softmax','tanh','sigmoid','exponential','linear' and more.\n","\n","Following are examples of two activation functions: RELU and Softmax. For softmax, we need to define the axis along which to apply the activation.\n","\n","Keras also provides some advanced activation functions which can learn parameters but these are out of scope for this tutorial."]},{"cell_type":"code","metadata":{"id":"-9aKmwKEXOJl","colab_type":"code","colab":{},"outputId":"62fd97c7-deb6-4f7f-d63a-59820bdc73f1"},"source":["from keras.layers.core import Activation                                        # Import Activation submodule from keras layers.core module\n","from keras import backend as K                                                  # Import keras backend\n","\n","randomtensor=K.random_uniform_variable(shape=(1,1,5,5),low=-2,high=5)           # A random uniform distribution tensor with lowest possible value = -2 and highest possible = 5\n","reluactivation=Activation('relu')                                               # Intialize relu activation \n","print('\\n\\t\\t\\tRELU ACTIVATION')\n","print('Input tensor: \\n',K.get_value(randomtensor))\n","\n","outtensor=reluactivation(randomtensor)                                          # Pass random tensor to relu activation to see its effects\n","print('\\nRelu Activation output: \\n',K.get_value(outtensor))\n","\n","print('-'*70)\n","print('\\n\\t\\t\\tSoftmax Activation')\n","randomtensor=K.random_uniform_variable(shape=(1,1,1,6),low=-2,high=5)           # random uniform distribution tensor of shape (1 x 1 x 1 x 6), lowest possible value = -2 and highest possible = 5\n","print('Input tensor: \\n',K.get_value(randomtensor))\n","softmaxactivation=Activation('softmax')                                         # Initializing softmax activation\n","outtensor=softmaxactivation(randomtensor)                                       # Passing random tensor to softmax activation layer\n","print('\\nSoftmax Activation output: \\n',K.get_value(outtensor))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","\t\t\tRELU ACTIVATION\n","Input tensor: \n"," [[[[ 2.0705428   4.8187284   1.7726908   4.627082   -1.7312672 ]\n","   [ 4.862919    4.722542   -0.840021    4.540087    1.2682633 ]\n","   [-0.36543572  3.1376042   2.9521737   2.066959   -1.3211952 ]\n","   [ 0.13226175  1.7998643   2.1514082   3.2197514   1.1830635 ]\n","   [ 2.38314     3.0333805   1.1642089   4.0897436   4.6930127 ]]]]\n","\n","Relu Activation output: \n"," [[[[2.0705428  4.8187284  1.7726908  4.627082   0.        ]\n","   [4.862919   4.722542   0.         4.540087   1.2682633 ]\n","   [0.         3.1376042  2.9521737  2.066959   0.        ]\n","   [0.13226175 1.7998643  2.1514082  3.2197514  1.1830635 ]\n","   [2.38314    3.0333805  1.1642089  4.0897436  4.6930127 ]]]]\n","----------------------------------------------------------------------\n","\n","\t\t\tSoftmax Activation\n","Input tensor: \n"," [[[[ 1.2252657   0.3615985   0.20155334 -0.65938103  4.581312\n","    -0.3194884 ]]]]\n","\n","Softmax Activation output: \n"," [[[[0.03244466 0.01367909 0.01165603 0.00492778 0.9303699  0.00692253]]]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ze0ihIWXOJp","colab_type":"text"},"source":["As we know that relu sets all negative values to zero and the rest of values remain same (as also shown in figure below), we can understand our output results now.\n","<img src=\"images/relu.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n","\n","And for softmax, it takes a vector of real numbers and normalizes the values into a probability distribution."]},{"cell_type":"markdown","metadata":{"id":"pEbjiS12XOJq","colab_type":"text"},"source":["### Dense Layer\n","We import dense layer from keras.layers.core submodule of keras. The parameters for dense layer are follows:\n","\n","**Dense(units, activation=None, use_bias=True)**\n","\n","* units: Number of neurons in the layer or number of dimensions in output.\n","* activation: Activation function to be applied to dense layer output. If this is None, then no activation is applied.\n","* use_bias: True if we want to use bias vector\n","\n","An input tensor is flattened before feeding into dense layer if its rank is greater than 2."]},{"cell_type":"code","metadata":{"id":"dNza8fUtXOJr","colab_type":"code","colab":{},"outputId":"7947f607-2878-48d4-f9e3-3a71753f69e1"},"source":["from keras.layers.core import Dense, Flatten                                    # Import Dense and Flatten submodule from keras layers.core module\n","from keras import backend as K                                                  # Import keras backend\n","\n","flatteninput=Flatten()\n","denselayer=Dense(16)\n","\n","randomtensor=K.random_uniform_variable(shape=(1,1,5,5),low=0,high=255)          # A random tensor with lowest value = 0 and highest value = 255\n","\n","print('Input tensor shape: ',randomtensor.shape,'\\n',K.get_value(randomtensor))\n","\n","outtensor=denselayer(flatteninput(randomtensor))                                # Flatten the input tensor\n","print('\\nOutput shape: ',outtensor.shape)\n"," \n","print('Dense Layer output: \\n',K.get_value(outtensor))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Input tensor shape:  (1, 1, 5, 5) \n"," [[[[116.745514  46.895596 172.45409  111.540245 183.3954  ]\n","   [ 96.42691   78.021065 225.5935    60.60836   18.71512 ]\n","   [ 85.22155   34.107853 170.36714  206.2946   103.72082 ]\n","   [ 64.65709  102.414566  20.466675 194.40715  159.80948 ]\n","   [138.83682  249.53848   15.266547  18.376392 138.70067 ]]]]\n","\n","Output shape:  (1, 16)\n","Dense Layer output: \n"," [[ -42.4599     71.85665   142.94595   157.31287    -8.780102 -126.94177\n","    32.009853  119.2424    119.61725    73.246895 -164.97363   108.78273\n","  -307.54883   -70.09828   318.86188    -4.682003]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qWlCiRL1XOJu","colab_type":"text"},"source":["## Model Building\n","The layers that have just covered are basic building blocks of a deep learning model. Now, we will stack them or combine them together to build our deep learning models. For now, we will build a simple model to help us understand the concept of deep learning models. Then, we will move to actual training model for classification tasks.\n","\n","Here, we will build a model of: \n","1. 1 Convolutional Layer\n","2. 1 Activation function\n","3. 1 Maxpool layer\n","4. 1 Dense Layer\n","5. 1 Final softmax layer\n","\n","Final Dense layer has neurons equal to the number of classes and the output of the final layer in a model is called logits. In our example, we will have a dense layer of 2 neurons (because we are building a model to classify between two classes)"]},{"cell_type":"code","metadata":{"id":"A8rmrDelXOJv","colab_type":"code","colab":{}},"source":["\n","from keras.models import Sequential                                             # First we import Sequential datastructure of keras\n","from keras.layers.core import Dense, Activation, Flatten                        # Import Dense, Activation and Flatten submodules from layers.core module of keras\n","from keras.layers.convolutional import Conv2D                                   # Import Conv2D submodule\n","from keras.layers import MaxPooling2D                                           # Import MaxPooling2D submodule\n","from keras import backend as K                                                  # Import keras backend\n","\n","\n","# We define our model as an instance of the data structure \n","model = Sequential()\n","\n","# Now, we will add layers to the model. First, we add convolutional layer with no activation and padding = 'valid'\n","model.add(Conv2D(8, (3,3), strides=(1, 1), padding='valid', activation=None, use_bias=True,data_format=\"channels_first\"))\n","\n","# Add relu activation\n","model.add(Activation('relu'))\n","\n","# Add maxpooling layer with padding='valid'\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=\"channels_first\"))\n","\n","# Here, we will have 3 dimensional tensor of some size. For Dense layer, we will flatten it out. \n","model.add(Flatten())\n","\n","# Dense layer with 2 output units\n","model.add(Dense(2,use_bias=True))\n","\n","# Softmax activation function\n","model.add(Activation('softmax'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q4AEozwIXOJy","colab_type":"text"},"source":["### Model Summary\n","Keras provides a method 'summary' to get the summary representation of our model. It lists down the layers of our model, their output shape and learnable parameters in each layer. To get the summary of a model, we either need to specify the input shape in the first layer of model or build the model with a specific input shape.\n","For example, summary of our model is given below:"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"hVd-q0kVXOJ0","colab_type":"code","colab":{},"outputId":"cb2999af-2814-439c-e833-07034eea4536"},"source":["model.build(input_shape=(1,3,64,64))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2 (Conv2D)            (1, 8, 62, 62)            224       \n","_________________________________________________________________\n","activation_3 (Activation)    (1, 8, 62, 62)            0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (1, 8, 31, 31)            0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (1, 7688)                 0         \n","_________________________________________________________________\n","dense_2 (Dense)              (1, 2)                    15378     \n","_________________________________________________________________\n","activation_4 (Activation)    (1, 2)                    0         \n","=================================================================\n","Total params: 15,602\n","Trainable params: 15,602\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Yu0Bjp8LXOJ3","colab_type":"text"},"source":["1. As our convolution layer has 8 kernels. Each kernel has a width and a height of 3 and depth of kernel is influenced by the number of channels in input tensor. In our case, our images has 3 channels and so, our each kernel has a total dimensions of (3 x 3 x 3). We need to train each value in each tensor to look for certain pattterns in the image and therefore we have tatal trainable parameters: **(3 * 3 * 3) * 8 + 8(bias vector) = 224**.\n","\n","\n","2. The output from flatten_2 layer is 7688 length vector. The Dense layer (dense_2) is a fully connected layer and has 2 neurons. Thus, the total parameters for dense layer are: **7688 * 2 (7688 connections from previous layer to each neuron) + 2 (bias units) = 15378**"]},{"cell_type":"markdown","metadata":{"id":"lA0PzXqZXOJ4","colab_type":"text"},"source":["**Model Execution**"]},{"cell_type":"code","metadata":{"id":"Uk_LxLinXOJ5","colab_type":"code","colab":{},"outputId":"ccaf576d-9894-407d-ae6d-c4eee1db33dd"},"source":["# Now that we have built our model, we would like to see how a certain input tensor will be transformed \n","# if passed through this model\n","\n","inputtensor=K.random_normal_variable(shape=(1,3,64,64),mean=0,scale=13)         # Random uniform variable of shape (1 x 3 x 64 x 64) with mean = 0 and standard deviation = 13\n","output=model(inputtensor)                                                       # Pass this random tensor to model\n","print('output shape: ',output.shape)\n","print('output values: \\n',K.get_value(output)[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["output shape:  (1, 2)\n","output values: \n"," [2.8046618e-14 1.0000000e+00]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xAlYTI4GXOJ8","colab_type":"text"},"source":["As you can see we have output of 2 values, both sum up to 1.0, which results from softmax activation."]},{"cell_type":"markdown","metadata":{"id":"9glzCMqhXOJ9","colab_type":"text"},"source":["## Model Compiling\n","All the examples that we have covered so far did not include any training. Layers were initialized and were used to process our input tensors. The weights or values of kernels were preinitialized. But to solve oiur problems, we want our kenel windows to look for specific patterns in input data and base their results on that. As we have already discussed how model training works in theoretical part, we will cover model training steps using keras here.\n","\n","After building our model, we need to compile it which means, we need to configure the learning process for our model which includes choosing loss function, learning rate, optimizer for weights updates etc. Keras provides compile function and some of the important arguments are mentioned here:\n","\n","**compile(optimizer, loss=None, metrics=None, loss_weights=None)**\n","\n","* optimizer: It can be a string value defining the name of optimizer or and instance of optimizer class. Keras provides a number of optimizers to choose from e.g. RMSProp, SGD, Adagrad, AdaDelta, Adam etc.\n","* loss: It can be a string value defining the name of loss function to use or can be a defined objective function. Keras provides some loss functions: 'mean_squared_error','mean_absolute_error', 'binary_crossentropy', 'categorical_crossentropy' etc.\n","* metrics: Metric quantifies the fitness of model to our data i.e. it measures how well the model fits the data. It can be a list of metrics that the model evaluates during training and testing. \n","* loss_weights: For multiple classes, we can assign different weights to different classes. It essentially means that a small loss value in one class would be penalized more than same value loss for any other class. This is particularly important for training on imbalanced dataset.\n","\n","Consider the configurations below where we have used categorical_crossentropy loss, accuracy metric and rmsprop optimizer for our model.\n","\n"]},{"cell_type":"code","metadata":{"id":"e6h18BkVXOJ-","colab_type":"code","colab":{}},"source":["Compile the built model (configure the learning process of the model) by specifying the optimizer used, loss used and metrics\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer='rmsprop')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rouI__iVXOKC","colab_type":"text"},"source":["## Data Building\n","Now, we have our built our model completely. To train this model, we need data. We will use some real world data later, but for our understanding, we will randomly generate some input tensors and will train our model. In this part, we will focus on learning how to feed data to a model.\n","\n","We will build a dummy data with 1000 random images of (64 x 64 x 3) dimension each. We have built a binary classifier model, which means that it can classify 2 classes and so, to use this model, we will somehow label these random images to 2 classes. Just for learning, we have used the mean of the sum of pixel values to assign classes to each image. Following are the steps:\n","\n","1. Sum of each image along all dimensions (64 x 64 x 3) is calculated.\n","2. Mean of sums is calculated.\n","3. All values greater or equal to mean are assigned class 1 while the rest are assigned class 0.\n","3. The class numbers are converted into one hot encoding (which is required format to be used to train the model).\n"]},{"cell_type":"code","metadata":{"id":"anG8m2MAXOKG","colab_type":"code","colab":{},"outputId":"4459d4ac-e15b-4711-ecf7-b0ea8d3804a8"},"source":["import numpy as np                                                              # Import numpy library\n","from keras.utils import to_categorical                                          # To preprocess the data. to_categorical is used to get data in one-hot encoding form\n","import matplotlib.pyplot as plt                                                 # Pyplot module of matplotlib\n","\n","totalsamples=1000                                                               # Number of total data points\n","#X=np.random.randint(low=0,high=255,size=(totalsamples,3,5,5))\n","X=np.random.uniform(low=0.0,high=1.0,size=(totalsamples,3,64,64))*255           # random uniform sample\n","X=X.astype(int)\n","sums=X.sum(axis=tuple(range(1,X.ndim)))                                         # Sum across all values of X across dimension = 1\n","mean=np.mean(sums)                                                              # Find all values sums\n","\n","labels=np.zeros(shape=sums.shape,dtype=int)\n","labels[sums>=mean]=1                                                            # Shortlist all the sums greater than mean\n","\n","# To show the distribution of our classes\n","plt.figure('Figure')\n","plt.title('Distribution of Labels',fontsize=14)\n","\n","l, counts = np.unique(labels, return_counts=True)                               # Find unique numbers\n","plt.bar(l, counts, align='center')                                              # Plot a bar of the counts that I have put in\n","plt.gca().set_xticks(l)\n","plt.ylim(0,650)\n","plt.show()\n","\n","print('X shape: ',X.shape)\n","print('Labels shape: ',labels.shape)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["X shape:  (1000, 3, 64, 64)\n","Labels shape:  (1000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8yki-YnSXOKL","colab_type":"text"},"source":["X shape values are as (batchsize,channels,height,width)"]},{"cell_type":"markdown","metadata":{"id":"fykKeY95XOKN","colab_type":"text"},"source":["### One Hot Encoding\n","To train our model, we need to provide our input images and their labels in correct format. Our images have 2 classes (0 and 1) and so, our labels are integer encoded (numbered 0 and 1). One hot encoding is used to represent our categorical variables as binary vectors(in the form of 0s and 1s). The length of the vector is equal to the number of classes. For a label integer, the binary vector has a 1 at the index of value and 0s at all other positions. To better understand this, consider following example:\n","\n","We have 5 classes: {0,1,2,3,4}\n","We can represent each of those values as a binary vector of length 5. Following are their binary vectors:\n","\n","* 0: [1,0,0,0,0]\n","* 1: [0,1,0,0,0]\n","* 2: [0,0,1,0,0]\n","* 3: [0,0,0,1,0]\n","* 4: [0,0,0,0,1]\n","\n","As you can see, all the values in a vector are 0 with 1 at the index position of that value. \n","\n","We can write custom code using numpy to get one hot encoded vectors or we can use keras library to do that.\n"]},{"cell_type":"code","metadata":{"id":"7BUF36LYXOKP","colab_type":"code","colab":{},"outputId":"42a01dd8-9a74-4940-b183-3e09eefbe089"},"source":["# In this cell, we will build one hot encoded vectors for categorical classes\n","import numpy as np                                                              #Import numpy library\n","classes=[0,1,2,3,4]                                                             # Total 5 classes\n","for c in classes:\n","    one_hot=np.zeros(shape=(len(classes)))                                      # A one hot encoded form of classes\n","    one_hot[c]=1\n","    print('Class',c,': ',one_hot)\n","print('\\n')\n","# Now, let's take another example of categorical variables\n","classes=['red','green','blue','orange','yellow','purple','indigo']\n","for idx,c in enumerate(classes):\n","    one_hot=np.zeros(shape=(len(classes)))\n","    one_hot[idx]=1\n","    print('%5s %7s %s %15s '%('Class',c,':',one_hot) )\n","    #print('Class',c,': ',one_hot)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Class 0 :  [1. 0. 0. 0. 0.]\n","Class 1 :  [0. 1. 0. 0. 0.]\n","Class 2 :  [0. 0. 1. 0. 0.]\n","Class 3 :  [0. 0. 0. 1. 0.]\n","Class 4 :  [0. 0. 0. 0. 1.]\n","\n","\n","Class     red : [1. 0. 0. 0. 0. 0. 0.] \n","Class   green : [0. 1. 0. 0. 0. 0. 0.] \n","Class    blue : [0. 0. 1. 0. 0. 0. 0.] \n","Class  orange : [0. 0. 0. 1. 0. 0. 0.] \n","Class  yellow : [0. 0. 0. 0. 1. 0. 0.] \n","Class  purple : [0. 0. 0. 0. 0. 1. 0.] \n","Class  indigo : [0. 0. 0. 0. 0. 0. 1.] \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"38Lftzn0XOKT","colab_type":"code","colab":{}},"source":["# Keras provides one line solution for this. So, we will use to_categorical to get our labels \n","# converted to one-hot encoding\n","one_hot_labels=to_categorical(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7upu0QRGXOKW","colab_type":"text"},"source":["Now we have 1000 input tensors and their labels to train our model. Before that, we will split our data into train, validation and test data. So, we can validate our results on the go and later test it. First, we will use sklearn's train_test_split function to split our data into train and test parts, then we will further divide the train set into train and validation set."]},{"cell_type":"code","metadata":{"id":"9DKMiMjiXOKX","colab_type":"code","colab":{},"outputId":"5c2e2dbe-4919-46e7-921b-ef3042359040"},"source":["from sklearn.model_selection import train_test_split\n","\n","# Following function will randomly shuffle our data and will split it into 80 - 20 percents(train and test data)\n","X_train,X_test,y_train,y_test=train_test_split(X,one_hot_labels,test_size=0.2,random_state=17)\n","\n","# Following function will divide train set into 90 - 10 split of train and validation set.\n","X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=43)\n","\n","print('X_train shape: ',X_train.shape)\n","print('y_train shape: ',y_train.shape)\n","\n","print('X_val shape  : ',X_val.shape)\n","print('y_val shape  : ',y_val.shape)\n","\n","print('X_test shape : ',X_test.shape)\n","print('y_test shape : ',y_test.shape)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X_train shape:  (720, 3, 64, 64)\n","y_train shape:  (720, 2)\n","X_val shape  :  (80, 3, 64, 64)\n","y_val shape  :  (80, 2)\n","X_test shape :  (200, 3, 64, 64)\n","y_test shape :  (200, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"re9nO_RfXOKa","colab_type":"text"},"source":["## Model Training\n","To train a model, we call \"fit\" function of the model. \n","\n","**fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1)**\n","\n","\n","* x: It is a numpy array of input training data e.g. images. In our case, it will contain our input tensors.\n","* y: It is also a numpy array of training data labels. In our case, it will contain one hot encoded vectors.\n","* batch_size: Number of samples provided to model for each run and for gradient calculation.\n","* epochs: Number of epoch represents the number of times, model will iterate through complete dataset. For example, epochs = 10 means that the model will iterate through the dataset 10 times.\n","* verbose: If verbose=1, in-between epochs results will be printed.\n","* callbacks: Function callbacks during training or validation. This is a list of functions that will be called during training or validation.\n","* validation_split: This is a value between 0 and 1. It represents the percentage of training data to be used for validation.\n","* validation_data: It is a tuple containing validation input data and labels (Xval,Yval). The model will be evaluated on this data after each epoch.\n","* shuffle: It is a boolean value. If shuffle=True, the data will be randomly shuffled before each iteration/epoch.\n","* initial_epoch: Epoch number to start the training from. It is useful to resume a previous training. \n","\n","This fit function returns a history object that contains records of training and validation losses and metrics values at successive epochs. Through this history object, we can visualize the losses and accuracies by plots."]},{"cell_type":"code","metadata":{"id":"kgbybXO7XOKb","colab_type":"code","colab":{}},"source":["history= model.fit(x=X_train,y=y_train,batch_size=1,epochs=2,verbose=1,validation_data=(X_val,y_val),shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dZpBh9klXOKh","colab_type":"text"},"source":["We trained the model for 2 epochs. Our validation results remained the same while our training accuracy increased and our training loss decreased a little. "]},{"cell_type":"code","metadata":{"id":"xQ1604A8XOKh","colab_type":"code","colab":{}},"source":["# This function will take history/output from train/test function.\n","def summarize_stats(history,title):\n","    # loss \n","    plt.figure(figsize=(16,4))                                                  # Set figure size\n","    plt.subplot(1,2,1)                                                          # Add subplots\n","    plt.suptitle(title,fontsize=18)                                             # Add suptitle\n","    plt.title('Loss',fontsize=16)                                               # Get a figure for loss\n","    plt.plot(history.history['loss'], color='red', label='Train')               # Plot history of the training/testing\n","    plt.plot(history.history['val_loss'], color='blue', label='Test')\n","    plt.legend(loc='upper right')\n","    # accuracy\n","    plt.subplot(1,2,2)\n","    plt.title('Classification Accuracy',fontsize=16)                            # Figure of classification accuracy\n","    plt.plot(history.history['acc'], color='red', label='Train')                # Plot accuracy from history plot\n","    plt.plot(history.history['val_acc'], color='blue', label='Test')            # Plot validation accuracy\n","\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","\n","summarize_stats(history,'Reuslts')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QaC-xY32XOKk","colab_type":"text"},"source":["## Pretrained Models and Fine Tuning\n","A deep learning model requires huge amount of data to train well and usually, for our particular problem, we only have access to a small dataset. If we train our model from scratch with randomly initialized weights, the model will most likely overfit the training set. To tackle this problem, we use models that have been pretrained on some large dataset and then we intialize our layers with weights of those models. This process is called fine-tuning. In finetuning, we tune the network parameters/weights of an already trained model so it can adapt to the new task. Initial layers in a model learn general features while last layers learn features specific to our task e.g. initial layers might learn circular edges, horizontal or vertical edges while last layers learn specific features like the shape of nose, lips, ear etc. Therefore, in finetuning, we only train the last few layers and freeze the initial layers. \n","To fine-tune a model, we replace last few layers to get our required number of classes as output and then we train the complete model. Keras provides models pretrained on ImageNet which we can use for our tasks. Some of those models are: VGG16, VGG19, InceptionV3, ResNet and DenseNet. \n","\n","Consider the example of using VGG16 provided by keras. We can import the models from keras.applications module. To initialize a model, we call the module with parameters:\n","\n","```VGG16(include_top=True, weights='imagenet', input_shape=None, pooling=None, classes=1000)```\n","\n","* include_top: If True, the last fully connected layers will be included and if False, last fully connected layers will be excluded.\n","\n","* weights: If None, then the model weights will be randomly initialized and if 'imagenet' then the weights of model trained on imagenet will be loaded.\n","\n","* input_shape: To specify shape of input tensor. It has to be specified only if include_top is False.\n","\n","* pooling: To be specified when include_top is False. This is for feature extraction. Possible values are: None for no pooling, 'avg' for average pooling and 'max' for max pooling applied to the output of last conv layer.\n","\n","* classes: Number to classes to classify images into. This should be specified only if include_top is True and weights is None. "]},{"cell_type":"code","metadata":{"id":"egjKbojZXOKk","colab_type":"code","colab":{}},"source":["from keras.applications import VGG16                                            # Import pretrained prebuilt VGG16 model architecture\n","vgg16=VGG16(weights='imagenet',input_shape=(224,224,3),include_top=True)        # Specifying the input shape and using weights of 'imagenet' trained model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XTYc6CUOXOKn","colab_type":"text"},"source":["### Model Summary\n","As we included top layers using include_top=True, we can look at the complete model:"]},{"cell_type":"code","metadata":{"id":"PsnDu1UgXOKo","colab_type":"code","colab":{},"outputId":"ae9319d3-6023-43e3-e5cf-968a1a483e4d"},"source":["vgg16.summary()                                                                 # Show VGG16 structure summary"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4xrh1izhXOKr","colab_type":"text"},"source":["### Steps for Fine Tuning:\n","To finetune this model, we need to remove last fully connected and flatten layers and add layers specific to solve our problem. For that, we need to follow these steps:\n","1. Load pretrained model and set include_top=False to remove last fully connected layers\n","2. Freeze initial layers because we do not want to train them\n","3. Build our own model on top of pretrained one.\n","4. Train the model"]},{"cell_type":"markdown","metadata":{"id":"ihKV9WUYXOKr","colab_type":"text"},"source":["#### Step 1: Load Pretrained Model\n","We will load pretrained VGG16 with include_top=False."]},{"cell_type":"code","metadata":{"id":"PtNQN7KTXOKs","colab_type":"code","colab":{},"outputId":"583b20f4-34da-4613-a768-6fbf715a242d"},"source":["from keras.applications import VGG16                                            # Import VGG16\n","vgg16=VGG16(weights='imagenet',input_shape=(224,224,3),include_top=False)       # Use ImageNet weights and no model on top\n","vgg16.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JzZPlwvsXOKw","colab_type":"text"},"source":["As you can see, the last FC layers have been removed and our last layers is a block5_pool layer."]},{"cell_type":"markdown","metadata":{"id":"_q37K3xNXOKw","colab_type":"text"},"source":["#### Step 2: Freeze Initial Layers\n","As we can see from model summary, it has 5 blocks and each block has conv and pool layers. We do not want to train initial layers so we will freeze all layers in first 4 blocks and will train the last 4 layers. Keras layers have a property 'trainable' and we can set it to False if we do not want to train a layer:"]},{"cell_type":"code","metadata":{"id":"PagmMgkoXOKx","colab_type":"code","colab":{},"outputId":"c6d46e86-51f5-4914-b8bb-e7a508326426"},"source":["for layer in vgg16.layers[:-4]:                                                 # Freeze the last 4 layers and train them accordingly\n","    layer.trainable=False\n","\n","#Checking layers which are trainable:\n","for layer in vgg16.layers:\n","    print(layer,layer.trainable)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<keras.engine.input_layer.InputLayer object at 0x7fb33bd95470> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bdad860> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bdada58> False\n","<keras.layers.pooling.MaxPooling2D object at 0x7fb33bd49f28> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bd49be0> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bd7bac8> False\n","<keras.layers.pooling.MaxPooling2D object at 0x7fb33bd13d68> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bd13e48> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bccbe10> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bcfa668> False\n","<keras.layers.pooling.MaxPooling2D object at 0x7fb33bc96dd8> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bc96a90> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bc48978> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bc65f98> False\n","<keras.layers.pooling.MaxPooling2D object at 0x7fb33bc199e8> False\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bc19518> True\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bbcd240> True\n","<keras.layers.convolutional.Conv2D object at 0x7fb33bbe4c50> True\n","<keras.layers.pooling.MaxPooling2D object at 0x7fb33bb9a588> True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D8aKp-bvXOK1","colab_type":"text"},"source":["#### Step 3: Build a model on top of pretrained\n","Since our pretrained model already has Conv and Pool layers, we can focus on adding fully connected layers only and add them on top of pretrained model. This provides us the flexibility to mold a model pretrained for some problem to our solve our own specific problem e.g. we can add layers for other problems like regression, image localization and image segmentation."]},{"cell_type":"code","metadata":{"id":"ROzccD8MXOK2","colab_type":"code","colab":{},"outputId":"09ee778d-5923-4d7f-c704-7648cef881e9"},"source":["from keras.models import Sequential                                             # Add sequential module from models in keras library\n","from keras.layers.core import Dense, Activation, Flatten                        # Import Dense, Activation and Flatten submodules of layers.core module\n","from keras.layers.convolutional import Conv2D                                   # Import convolutional layer from keras.layers\n","from keras.layers import MaxPooling2D                                           # Import maxpooling layer from keras.layers\n","from keras.layers import Dropout                                                # Import dropout layer from keras\n","\n","def build_model_finetune(basemodel):\n","    model=Sequential()                                                          # A sequential array which can contain the model layers\n","  \n","    # Add base model\n","    model.add(basemodel)                                                        # Add basic VGG16 initially\n","\n","    # Flatten the image pixels\n","    model.add(Flatten())                                                        # Flatten out the output from VGG16\n","\n","    # Add fully connected layers\n","    model.add(Dense(512))                                                       # A dense layer with 512 output units\n","    model.add(Activation('relu'))                                               # A relu activation function\n","    model.add(Dropout(0.2))                                                     # A dropout of 0.2\n","\n","    # A fully connected layer for 2 classes\n","    model.add(Dense(2))\n","\n","    #a softmax to get probabilities of each class\n","    model.add(Activation('softmax'))\n","\n","    return model\n","\n","model = build_model_finetune(vgg16)\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='rmsprop')\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Model)                (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 25088)             0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 512)               12845568  \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 2)                 1026      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 2)                 0         \n","=================================================================\n","Total params: 27,561,282\n","Trainable params: 19,926,018\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VogB6JDWXOK5","colab_type":"text"},"source":["As you can see, the model now has vgg16 as base model and our defined layers are on top of base model for classifying two classes."]},{"cell_type":"markdown","metadata":{"id":"9H77dHj4XOK6","colab_type":"text"},"source":["#### Step 4: Train the model\n","Finally, we train the model using .fit() function provided by Keras as explained above."]},{"cell_type":"code","metadata":{"id":"Sej77BthXOK7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}